{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 17:02:56.755881: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-03 17:02:56.760226: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-03 17:02:56.772548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-03 17:02:56.792997: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-03 17:02:56.798842: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-03 17:02:56.813585: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-03 17:02:57.994675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " 'test': <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " 'unsupervised': <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 25000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 17:03:09.017335: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=2>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=3>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=4>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=5>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=6>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=7>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in train_dataset.range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 17:03:17.171987: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.map(lambda text, label: text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"Vocabulary limitation: It caps the number of unique words the model will consider, which helps manage computational complexity and memory usage. Handling rare words: Words that are not in the top 1000 most frequent will be treated as out-of-vocabulary (OOV) tokens.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10000\n",
      "First 10 words in the vocabulary:\n",
      "['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']\n",
      "\n",
      "Sample text: This movie was great! I really enjoyed it.\n",
      "Vectorized form:\n",
      "[[ 11  18  14  85  10  63 492   9]]\n",
      "\n",
      "Decoded text:\n",
      "this movie was great i really enjoyed it\n",
      "\n",
      "OOV text: This movie was supercalifragilisticexpialidocious!\n",
      "Vectorized form:\n",
      "[[11 18 14  1]]\n",
      "\n",
      "Decoded OOV text:\n",
      "this movie was [UNK]\n"
     ]
    }
   ],
   "source": [
    "# Check the vocabulary\n",
    "vocab = encoder.get_vocabulary()\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "print(\"First 10 words in the vocabulary:\")\n",
    "print(vocab[:10])\n",
    "\n",
    "# Check vectorization of a sample text\n",
    "sample_text = \"This movie was great! I really enjoyed it.\"\n",
    "vectorized_text = encoder(tf.constant([sample_text]))\n",
    "print(\"\\nSample text:\", sample_text)\n",
    "print(\"Vectorized form:\")\n",
    "print(vectorized_text.numpy())\n",
    "\n",
    "# Decode the vectorized text back to words\n",
    "decoded_text = [vocab[i] for i in vectorized_text[0] if i != 0]\n",
    "print(\"\\nDecoded text:\")\n",
    "print(\" \".join(decoded_text))\n",
    "\n",
    "# Check out-of-vocabulary handling\n",
    "oov_text = \"This movie was supercalifragilisticexpialidocious!\"\n",
    "vectorized_oov = encoder(tf.constant([oov_text]))\n",
    "print(\"\\nOOV text:\", oov_text)\n",
    "print(\"Vectorized form:\")\n",
    "print(vectorized_oov.numpy())\n",
    "\n",
    "decoded_oov = [vocab[i] for i in vectorized_oov[0] if i != 0]\n",
    "print(\"\\nDecoded OOV text:\")\n",
    "print(\" \".join(decoded_oov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        encoder,\n",
    "        layers.Embedding(\n",
    "            input_dim=len(encoder.get_vocabulary()), output_dim=64, mask_zero=True\n",
    "        ),\n",
    "        layers.Bidirectional(layers.SimpleRNN(64)),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized text shape: (1, 19)\n",
      "Vectorized text dtype: <dtype: 'int64'>\n",
      "Vectorized text:\n",
      "[[   2   18   14  652    2  737    3    2 2916   66   46    5   11  188\n",
      "    10   59  368   11   18]]\n"
     ]
    }
   ],
   "source": [
    "sample_text = (\n",
    "    \"The movie was cool. The animation and the graphics \"\n",
    "    \"were out of this world. I would recommend this movie.\"\n",
    ")\n",
    "\n",
    "# Check the output of the TextVectorization layer\n",
    "vectorized_text = encoder(tf.constant([sample_text]))\n",
    "print(\"Vectorized text shape:\", vectorized_text.shape)\n",
    "print(\"Vectorized text dtype:\", vectorized_text.dtype)\n",
    "print(\"Vectorized text:\")\n",
    "print(vectorized_text.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=False>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape of TextVectorization: (1, 19)\n",
      "Output dtype: <dtype: 'int64'>\n",
      "tf.Tensor(\n",
      "[[   2   18   14  652    2  737    3    2 2916   66   46    5   11  188\n",
      "    10   59  368   11   18]], shape=(1, 19), dtype=int64)\n",
      "\n",
      "\n",
      "Output shape of Embedding: (1, 19, 64)\n",
      "Output dtype: <dtype: 'float32'>\n",
      "tf.Tensor(\n",
      "[[[-0.04120809  0.03969653 -0.00851754 ...  0.03240068  0.01108141\n",
      "    0.00140482]\n",
      "  [ 0.03155328 -0.00747095 -0.0040307  ...  0.03335286  0.0267132\n",
      "    0.00785368]\n",
      "  [ 0.01387639 -0.01176424  0.01484444 ...  0.01976022  0.01416189\n",
      "   -0.00150902]\n",
      "  ...\n",
      "  [ 0.0030445   0.02384514 -0.02981331 ... -0.03997167  0.00829545\n",
      "   -0.03643908]\n",
      "  [-0.03338809  0.03482658  0.01629212 ... -0.0320698  -0.0141362\n",
      "   -0.02827463]\n",
      "  [ 0.03155328 -0.00747095 -0.0040307  ...  0.03335286  0.0267132\n",
      "    0.00785368]]], shape=(1, 19, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Output shape of Bidirectional: (1, 128)\n",
      "Output dtype: <dtype: 'float32'>\n",
      "tf.Tensor(\n",
      "[[-0.34509483  0.03049743 -0.04667048 -0.08121324 -0.19355151  0.06434804\n",
      "   0.14070514  0.03229159 -0.08629321  0.03138221 -0.19683862  0.1542403\n",
      "  -0.10968723  0.07641117  0.30451587  0.01331877 -0.11067342  0.12992795\n",
      "   0.06562478  0.15191573 -0.07982957 -0.03397901  0.18399236  0.03869671\n",
      "  -0.12991606  0.1658256  -0.00170197  0.2071166   0.01690696  0.28486592\n",
      "  -0.14033736 -0.07106258  0.04434055 -0.01679622  0.04824866 -0.12925534\n",
      "   0.0788839   0.06173164  0.1688971  -0.0286349   0.05367794  0.06657697\n",
      "   0.09798357  0.1080703   0.12004644  0.16345975 -0.07409214  0.1811015\n",
      "  -0.07187793 -0.03351971  0.12299292  0.15128803 -0.065296   -0.09384552\n",
      "   0.05825901 -0.12343931  0.03648714  0.05020563  0.15955928 -0.0219309\n",
      "  -0.03091938  0.02553909  0.08092248  0.06141233 -0.11923252 -0.2018315\n",
      "   0.0541673   0.07480443 -0.14275068 -0.02690582  0.01632404  0.0432927\n",
      "  -0.22539772 -0.2637967  -0.11395927  0.14107528 -0.01470433 -0.1707259\n",
      "   0.01047851 -0.12339498  0.00415541  0.08144819 -0.0187577   0.15637873\n",
      "   0.04918063 -0.06189397  0.12811708 -0.08445725 -0.11685093  0.12774454\n",
      "   0.03685571 -0.04957755 -0.28769964  0.18436429 -0.1521993  -0.01475625\n",
      "  -0.07353488  0.11369466 -0.01093439 -0.10039342 -0.15078306  0.13610956\n",
      "   0.05815254 -0.01626125  0.01994912  0.04438732  0.14935543  0.07312718\n",
      "  -0.09828857  0.06801914 -0.0876352  -0.09463139  0.09312021 -0.13566385\n",
      "   0.06189786 -0.15714897 -0.2183389  -0.14192943 -0.18976972  0.23568606\n",
      "   0.0561114  -0.04901927  0.12385985 -0.06737334 -0.11122595 -0.02971903\n",
      "   0.10927751 -0.14769341]], shape=(1, 128), dtype=float32)\n",
      "\n",
      "\n",
      "Output shape of Dense: (1, 64)\n",
      "Output dtype: <dtype: 'float32'>\n",
      "tf.Tensor(\n",
      "[[0.         0.         0.03799941 0.14028202 0.09540856 0.\n",
      "  0.         0.14372574 0.14253849 0.05411141 0.01584193 0.\n",
      "  0.00659608 0.0111253  0.0216583  0.11629252 0.         0.2519067\n",
      "  0.08251741 0.         0.         0.         0.09290959 0.00028284\n",
      "  0.         0.08602396 0.15909034 0.         0.18884602 0.00971732\n",
      "  0.         0.07578917 0.08226965 0.         0.         0.\n",
      "  0.00800018 0.09962586 0.05082061 0.08026937 0.08234771 0.\n",
      "  0.13924412 0.         0.         0.00585091 0.08889136 0.\n",
      "  0.14303672 0.         0.         0.25083786 0.15123881 0.\n",
      "  0.         0.21567105 0.         0.24852675 0.1790056  0.\n",
      "  0.02169505 0.09417067 0.         0.09052119]], shape=(1, 64), dtype=float32)\n",
      "\n",
      "\n",
      "Output shape of Dense: (1, 1)\n",
      "Output dtype: <dtype: 'float32'>\n",
      "tf.Tensor([[0.4595887]], shape=(1, 1), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the output of each layer\n",
    "for index, layer in enumerate(model.layers):\n",
    "    if index == 0:\n",
    "        intermediate_output = layer(np.array([sample_text]))\n",
    "    else:\n",
    "        intermediate_output = layer(intermediate_output)\n",
    "    print(f\"Output shape of {layer.__class__.__name__}: {intermediate_output.shape}\")\n",
    "    print(f\"Output dtype: {intermediate_output.dtype}\")\n",
    "    print(intermediate_output)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ts-wks-45/anaconda3/envs/ml/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:707: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 268ms/step - accuracy: 0.5269 - loss: 0.6911 - val_accuracy: 0.5578 - val_loss: 0.6823\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 268ms/step - accuracy: 0.6003 - loss: 0.6642 - val_accuracy: 0.7453 - val_loss: 0.5619\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 272ms/step - accuracy: 0.7872 - loss: 0.4871 - val_accuracy: 0.8625 - val_loss: 0.3424\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 267ms/step - accuracy: 0.8673 - loss: 0.3887 - val_accuracy: 0.8562 - val_loss: 0.3455\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 290ms/step - accuracy: 0.9168 - loss: 0.2270 - val_accuracy: 0.8698 - val_loss: 0.3443\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 308ms/step - accuracy: 0.9375 - loss: 0.1769 - val_accuracy: 0.8672 - val_loss: 0.3758\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 289ms/step - accuracy: 0.9468 - loss: 0.1539 - val_accuracy: 0.8672 - val_loss: 0.3880\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 271ms/step - accuracy: 0.9671 - loss: 0.1083 - val_accuracy: 0.8661 - val_loss: 0.3703\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 283ms/step - accuracy: 0.9794 - loss: 0.0722 - val_accuracy: 0.8516 - val_loss: 0.4404\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 291ms/step - accuracy: 0.9895 - loss: 0.0442 - val_accuracy: 0.8646 - val_loss: 0.5384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:54:27.881679: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 66ms/step - accuracy: 0.8616 - loss: 0.5376\n",
      "Test loss: 0.5264281630516052\n",
      "Test accuracy: 0.8628799915313721\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    train_dataset, epochs=10, validation_data=test_dataset, validation_steps=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - accuracy: 0.8616 - loss: 0.5376\n",
      "Test loss: 0.5264281630516052\n",
      "Test accuracy: 0.8628799915313721\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: str7392",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYour presentation was incredibly engaging and well-structured, showcasing your deep understanding of the topic; however, some of the slides were a bit text-heavy, which made it challenging for the audience to follow along at times.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/optree/ops.py:747\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    745\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    746\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dtype: str7392"
     ]
    }
   ],
   "source": [
    "model.predict(\n",
    "    np.array(\n",
    "        [\n",
    "            \"Your presentation was incredibly engaging and well-structured, showcasing your deep understanding of the topic; however, some of the slides were a bit text-heavy, which made it challenging for the audience to follow along at times.\"\n",
    "        ]\n",
    "    ),\n",
    "    batch_size=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
